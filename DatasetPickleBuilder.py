#
# Takes the files generated by Webscraper.py and creates a usable dataset to train some classifier on
#


import os
import json
import pprint
import re
import pickle

classes = {"wall", "wallbreaker", "sweeper", "glasscannon", "pivot", "utility", "revengekiller", "spinblocker", "stallbreaker", "tank", "support", "supporter", "trapper"}


def findkeywords(description, classes):
    description = description.replace("glass cannon", "glasscannon")
    description = description.replace("revenge killer", "revengekiller")

    words = {e for e in re.compile(r"\W+").split(description)}

    return words.intersection(classes)


files = os.listdir("pokemonListings/")
dataset = []

for file in files:
    f = open("pokemonListings/" + file, 'r')
    data = json.loads(f.read())
    f.close()

    if not data["strategies' format"] in {"OU", "UU", "RU"}:
        continue

    overviewkeywords = findkeywords(data["overview"], classes)

    for strategy in data["strategies"]:
        keywords = findkeywords(strategy["usage"], classes).union(findkeywords(strategy["name"], classes)).union(overviewkeywords)

        if len(keywords) == 0:
            continue

        featureValues = {"stats":   strategy["stats"],
                         "item":    {e for e in strategy["item"]},
                         "ability": {e for e in strategy["ability"]},
                         "type":    {e for e in strategy["type"]},
                         "moves":   {elem for lis in strategy["moves"] for elem in lis}
                         }

        dataset.append({"labels": keywords,
                     "features": featureValues,
                     "name": data["name"] + " - " + strategy["name"]
                     })

f = open("dataset_pickle", 'wb')
pickle.dump(dataset, f)
f.close()
